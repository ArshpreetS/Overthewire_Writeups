## Robots.txt 

This is a text file used to instruct the web crawlers (generally the web search engines) how to crawl their website. In easy words this text file is used allow certain user agents to and not to crawl parts of website.

*Note: REP --> Robot Exclusion Protocol --> a group of web standards that regulate how robots crawl the web, access and index content, and serve that content up to users*


### Basic Format

User-agent: [user-agent-name] Disallow: [url string not to be crawled]


## Referer Request Header

This includes the full or partial url of the page from which the user is requesting the page.